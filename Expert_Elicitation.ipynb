{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies for accessing MySQL database\n",
    "from sqlalchemy import create_engine\n",
    "from config import password\n",
    "\n",
    "# Dependencies for data analyses and dataframe building\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Dependencies for creating co-occurrence matrices\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "\n",
    "# Dependencies for visualising co-occurrence matrices\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Dependencies for creating dummy variables\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Dependencies for unsupervised learning\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_matrix(corpus):\n",
    "    \"\"\" Create a co-occurrence matrix \"\"\"\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    # Create bigrams\n",
    "    bi_grams = list(bigrams(corpus))\n",
    "    \n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "    \n",
    "    # Initialise co-occurrence matrix\n",
    "    # co_occurrence_matrix[current][previous]\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    "    \n",
    "    # Loop through the bigrams taking the current and previous word,\n",
    "    # and the number of occurrences of the bigram.\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        pos_current = vocab_index[current]\n",
    "        pos_previous = vocab_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    " \n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix, vocab_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset -- dishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the database connection\n",
    "engine = create_engine(f\"mysql+pymysql://root:{password}@localhost/dishes_db\")\n",
    "db_conn = engine.connect()\n",
    "\n",
    "# Create a dataframe based on a query for the GSR embedding of the \n",
    "# dishes and occasions by state\n",
    "df = pd.read_sql(\"select * from expert_elicitation limit 300\", db_conn)\n",
    "\n",
    "# Close the connection\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>State</th>\n",
       "      <th>Occasion</th>\n",
       "      <th>Dish</th>\n",
       "      <th>Dish2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>Bara</td>\n",
       "      <td>Bara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>Bread Sandwich</td>\n",
       "      <td>Sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>Chakuli</td>\n",
       "      <td>Chakuli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>Chatua</td>\n",
       "      <td>Chatua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>Chole/Guguni</td>\n",
       "      <td>Chole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   State   Occasion            Dish     Dish2\n",
       "0   1  Odisha  Breakfast            Bara      Bara\n",
       "1   2  Odisha  Breakfast  Bread Sandwich  Sandwich\n",
       "2   3  Odisha  Breakfast         Chakuli   Chakuli\n",
       "3   4  Odisha  Breakfast          Chatua    Chatua\n",
       "4   5  Odisha  Breakfast    Chole/Guguni     Chole"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe\n",
    "# Dish1 = original value from expert elicitation\n",
    "# Dish2 = equivalent name (to reduce sparsity of dish name values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe(df, state):\n",
    "    x = df.loc[df[\"State\"] == state].drop_duplicates() \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dish_count(df, states):\n",
    "    \"\"\" Count the number of dishes \"\"\"\n",
    "    dish_count = []\n",
    "    for x in states:\n",
    "        dish_count_dict = {}\n",
    "        for i in df.loc[df[\"State\"] == x][\"Occasion\"]:\n",
    "            if i in dish_count_dict:\n",
    "                dish_count_dict[i] += 1\n",
    "            else:\n",
    "                dish_count_dict[i] = 1\n",
    "        dish_count.append(dish_count_dict)    \n",
    "\n",
    "    return dish_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Breakfast': 22,\n",
       "  'AM Snack': 4,\n",
       "  'Lunch': 20,\n",
       "  'PM Snack': 21,\n",
       "  'Dinner': 20,\n",
       "  'Special Occasion': 21},\n",
       " {'Breakfast': 22,\n",
       "  'Lunch': 20,\n",
       "  'PM Snack': 19,\n",
       "  'Dinner': 20,\n",
       "  'Special Occasion': 19,\n",
       "  'AM Snack': 5}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [\"Odisha\", \"West Bengal\"]\n",
    "\n",
    "# How many dishes per occasion (all occasions)\n",
    "dish_count(df, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87 unique dishes in Odisha.\n",
      "There are 96 unique dishes in West Bengal.\n"
     ]
    }
   ],
   "source": [
    "# Create individual dataframes by state (and put them in a list)\n",
    "df_state = [dataframe(df, state) for state in states]  \n",
    "\n",
    "# Print number of unique dishes\n",
    "for x in range(0, len(states)):\n",
    "    print(f\"There are {len(df_state[x].Dish.unique())} unique dishes in {states[x]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 108 dishes in Odisha\n",
      "There are 105 dishes in West Bengal\n"
     ]
    }
   ],
   "source": [
    "# How many dishes are mentioned per state\n",
    "for x in range(0, len(states)):\n",
    "    print(f\"There are {len(df_state[x].Dish)} dishes in {states[x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Odisha\n",
      "Unique dishes: 74\n",
      "Total dishes: 87\n",
      "---\n",
      "State: West Bengal\n",
      "Unique dishes: 81\n",
      "Total dishes: 86\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Exclude special occasions in dataframe\n",
    "df2 = df.loc[df[\"Occasion\"] != \"Special Occasion\"]\n",
    "\n",
    "# How many dishes per occasion (without special occasions)\n",
    "dish_count(df2, states)\n",
    "\n",
    "# Create individual dataframes by state (and put them in a list)\n",
    "df_state2 = [dataframe(df2, state) for state in states]\n",
    "\n",
    "# Print number of unique dishes\n",
    "for x in range(0, len(states)):\n",
    "    print(f\"State: {states[x]}\")\n",
    "    print(f\"Unique dishes: {len(df_state2[x].Dish.unique())}\")\n",
    "    print(f\"Total dishes: {len(df_state2[x].Dish)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Dish</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Chapati</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Luchi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Cake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Khichdi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Payesh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Upma (sooji upma)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Vada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Vegetable Fry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Vegetable Pakoda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Watered Rice (Pakhala)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           State                    Dish  Count\n",
       "98   West Bengal                 Chapati      3\n",
       "135  West Bengal                   Luchi      3\n",
       "97   West Bengal                    Cake      2\n",
       "133  West Bengal                 Khichdi      2\n",
       "153  West Bengal                  Payesh      2\n",
       "..           ...                     ...    ...\n",
       "82        Odisha       Upma (sooji upma)      1\n",
       "83        Odisha                    Vada      1\n",
       "84        Odisha           Vegetable Fry      1\n",
       "85        Odisha        Vegetable Pakoda      1\n",
       "86        Odisha  Watered Rice (Pakhala)      1\n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many times a dish is mentioned per state\n",
    "dish_grouped = df.groupby([\"State\", \"Dish\"])[\"Dish\"].count().to_frame(\"Count\")\\\n",
    "               .reset_index()\n",
    "dish_grouped.sort_values([\"State\",\"Count\"], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 21 mentioned dishes from West Bengal\n",
    "dish_grouped[dish_grouped[\"State\"] == \"West Bengal\"].sort_values(\"Count\", ascending = False).head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 21 mentioned dishes from Odisha\n",
    "dish_grouped[dish_grouped[\"State\"] == \"Odisha\"].sort_values(\"Count\", ascending = False).head(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times a dish is mentioned in both states\n",
    "dish_grouped2 = df.groupby(\"Dish2\")[\"Dish2\"].count().to_frame(\"Count\").reset_index()\n",
    "dish_grouped2.sort_values(\"Count\", ascending = False).head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common dishes between states (occasions differ)\n",
    "dishes_common = pd.merge(df_state[0][[\"State\", \"Occasion\", \"Dish2\"]],\n",
    "                         df_state[1][[\"State\", \"Occasion\", \"Dish2\"]],\n",
    "                         on = \"Dish2\").drop_duplicates()\n",
    "dishes_common.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the common dishes between states\n",
    "dishes_common[\"Dish2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique dishes\n",
    "dishes_common[\"Dish2\"].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create co-occurrence matrices (dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries of dish lists by occasion \n",
    "# 0 = Odisha; 1 = West Bengal\n",
    "dicts_state = [df_state[x].groupby(\"Occasion\")[\"Dish2\"].apply(list).to_dict()\\\n",
    "              for x in range(0, len(df_state))]\n",
    "\n",
    "# Create a list of dish lists\n",
    "dish_lists = [[dicts_state[x][y] for y in dicts_state[x]] \\\n",
    "              for x in range(0, len(dicts_state))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of co-occurrence matrices\n",
    "coo_matrices = []\n",
    "for x in range(0, len(states)):\n",
    "    data = list(itertools.chain.from_iterable(dish_lists[x])) # flat list of dishes\n",
    "    matrix, vocab_index = coo_matrix(data)\n",
    "    data_matrix = pd.DataFrame(matrix, index=vocab_index, columns=vocab_index)\n",
    "    \n",
    "    # Save the co-occurrence matrix as csv\n",
    "    data_matrix.to_csv(f\"coo-matrix_{states[x]}.csv\", header = True)\n",
    "    \n",
    "    # Append co-occurrence matrix to list   \n",
    "    coo_matrices.append(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview one of the co-occurrence matrices\n",
    "coo_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset -- ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the database connection\n",
    "engine = create_engine(f\"mysql+pymysql://root:{password}@localhost/dishes_db\")\n",
    "db_conn = engine.connect()\n",
    "\n",
    "# Create a dataframe based on a query for the GSR embedding of the \n",
    "# dishes and occasions by state\n",
    "df_ing = pd.read_sql(\"select * from ingredients limit 1000\", db_conn)\n",
    "\n",
    "# Close the connection\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the list of dishes and ingredients\n",
    "# NB: \"Ingredient2\" ingredient groups to reduce sparsity (e.g., aloo = potato)\n",
    "df_ing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dishes from Odisha\n",
    "df_ing_OD = df_ing[df_ing[\"Odisha\"] == 1][[\"Id\", \"Dish\", \"Ingredient\", \"Ingredient2\", \"Ing_Category\"]]\n",
    "\n",
    "# Dishes from West Bengal\n",
    "df_ing_WB = df_ing[df_ing[\"West_Bengal\"] == 1][[\"Id\", \"Dish\", \"Ingredient\", \"Ingredient2\", \"Ing_Category\"]]\n",
    "\n",
    "# Create a list of dataframes\n",
    "dfs_ing = [df_ing_OD, df_ing_WB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_ing[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of ingredients per dish\n",
    "# Create a list of dataframes for Odisha [0] and West Bengal [1]\n",
    "ing_counts = [df.groupby(\"Dish\")[\"Ingredient\"].count().reset_index() for df in dfs_ing]\n",
    "\n",
    "# Preview list of dataframes\n",
    "ing_counts[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of summary statistics\n",
    "# Odisha [0]; West Bengal [1]\n",
    "num_ing = [len(df[\"Ingredient2\"].unique()) for df in dfs_ing] # number of ingredients per state\n",
    "means = [round(df[\"Ingredient\"].mean()) for df in ing_counts] # average\n",
    "stds = [round(df[\"Ingredient\"].std()) for df in ing_counts]   # standard deviation\n",
    "mins = [round(df[\"Ingredient\"].min()) for df in ing_counts]   # minimum\n",
    "maxs = [round(df[\"Ingredient\"].max()) for df in ing_counts]   # maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of results\n",
    "for x in range(0, len(means)):\n",
    "    print(f\"State: {states[x]}\")\n",
    "    print(\"------------------\")\n",
    "    print(f\"Number of ingredients: {num_ing[x]}\")\n",
    "    print(f\"Average number of ingredients per dish: {means[x]} ± {stds[x]}\")\n",
    "    print(f\"Minimum number of ingredients per dish: {mins[x]}\")\n",
    "    print(f\"Maximum number of ingredients per dish: {maxs[x]}\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a density plot to show frequency of ingredient length for both states\n",
    "plt.figure(figsize=(10,10))\n",
    "for count in ing_counts:\n",
    "    sns.distplot(count[\"Ingredient\"], hist = False, kde = True,\n",
    "                kde_kws = {\"linewidth\": 3})\n",
    "    \n",
    "plt.xlim((-5, 30))\n",
    "plt.ylim((0, 0.12))\n",
    "plt.xlabel(\"Number of ingredients\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "plt.savefig(\"EastIndia_Expert_Elicitation/density_ODWB.eps\", format = \"eps\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the most common ingredients per state\n",
    "# Odisha [0]; West Bengal [1]\n",
    "common_ingredients = []\n",
    "for x in dfs_ing:\n",
    "    df = x.groupby(\"Ingredient2\")[\"Ingredient\"].count().to_frame(\"Count\").reset_index()\n",
    "    df = df.sort_values(by = [\"Count\"], ascending = False)\n",
    "    common_ingredients.append(df)\n",
    "    \n",
    "# Merge the two dataframes and rename columns\n",
    "common_ingredients2 = pd.merge(common_ingredients[0], common_ingredients[1], how = \"outer\", on = \"Ingredient2\")\n",
    "common_ingredients2 = common_ingredients2.rename(columns = {\"Count_x\": \"Odisha\", \"Count_y\": \"West Bengal\"})\n",
    "\n",
    "# Preview the results    \n",
    "common_ingredients2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of ingredient categories by state\n",
    "# Odisha [0]; West Bengal [1]\n",
    "ing_category = []\n",
    "for x in dfs_ing:\n",
    "    df = x.groupby(\"Ing_Category\")[\"Ingredient\"].count().to_frame(\"Count\").reset_index()\n",
    "    df = df.sort_values(by = [\"Count\"], ascending = False)\n",
    "    ing_category.append(df)\n",
    "\n",
    "# Merge the two dataframes and rename columns\n",
    "ing_category2 = pd.merge(ing_category[0], ing_category[1], how = \"outer\", on = \"Ing_Category\")\n",
    "ing_category2 = ing_category2.rename(columns = {\"Count_x\": \"Odisha\", \"Count_y\": \"West Bengal\"})\n",
    "\n",
    "# Preview the results    \n",
    "ing_category2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical comparison of ingredient categories\n",
    "ind = np.arange(len(ing_category2))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.barh(ind, list(ing_category2[\"Odisha\"]), width, label = \"Odisha\")\n",
    "plt.barh(ind + width, list(ing_category2[\"West Bengal\"]), width, label = \"West Bengal\")\n",
    "\n",
    "plt.ylabel(\"Ingredient Category\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.yticks(ind + width/2, ing_category2[\"Ing_Category\"])\n",
    "plt.legend(loc = \"best\")\n",
    "plt.savefig(\"EastIndia_Expert_Elicitation/barh_ingredient_categories.eps\", format = \"eps\", dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of ingredient categories by state and by dish\n",
    "# Odisha [0]; West Bengal [1]\n",
    "ing_category2 = []\n",
    "for x in dfs_ing:\n",
    "    df = x.groupby([\"Dish\",\"Ing_Category\"])[\"Ingredient\"].count().to_frame(\"Count\").reset_index()\n",
    "    df = df.sort_values(by = [\"Count\"], ascending = False)\n",
    "    ing_category2.append(df)\n",
    "    \n",
    "# Preview the results    \n",
    "ing_category2[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis of dishes based on ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ingredients to dummy variables (one hot encoding) and convert to dataframes\n",
    "# Create list of dataframes of dummies: Odisha [0]; West Bengal [1]\n",
    "dfs_ing2 = []\n",
    "for x in range(0, len(dfs_ing)):\n",
    "    v = DictVectorizer(sparse = False)\n",
    "    grouped = dfs_ing[x].groupby(\"Dish\")[\"Ingredient2\"].apply(lambda lst: tuple((k, 1) for k in lst))\n",
    "    cat_dicts = [dict(tuples) for tuples in grouped]\n",
    "    X = v.fit_transform(cat_dicts)\n",
    "    df = pd.DataFrame(X, columns = v.get_feature_names(), index = grouped.index)\n",
    "    \n",
    "    # Save the one-hot-encoded matrix as csv\n",
    "    df.to_csv(f\"ingredients_{states[x]}.csv\", header = True)\n",
    "    \n",
    "    # Append one-hot-encoded matrix to list\n",
    "    dfs_ing2.append(df)\n",
    "    \n",
    "# Preview the dummy variables\n",
    "dfs_ing2[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the number of clusters for K-modes clustering using the silhouette method\n",
    "# Reference: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "def no_clusters(df):\n",
    "    # Establish a range of clusters    \n",
    "    range_n_clusters = list(range(2, 15))\n",
    "    \n",
    "    # Create an empty list of silhouette averages    \n",
    "    silhouette_avgs = []\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = KModes(n_clusters = n_clusters, init = 'Huang', n_init = 10, verbose = 0, random_state = 10)\n",
    "        cluster_labels = clusterer.fit_predict(df)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(df, cluster_labels)\n",
    "        silhouette_avgs.append(silhouette_avg)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(df, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                    c=colors, edgecolor='k')\n",
    "\n",
    "        # Labeling the clusters\n",
    "        centers = clusterer.cluster_centroids_\n",
    "        # Draw white circles at cluster centers\n",
    "        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=50, edgecolor='k')\n",
    "\n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                      \"with n_clusters = %d\" % n_clusters),\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "    return range_n_clusters, silhouette_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments = [no_clusters(df) for df in dfs_ing2]\n",
    "cluster_assignments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use silhouette averages to determine the optimal number of clusters (peak)\n",
    "for x in range(0, len(cluster_assignments)):\n",
    "    plt.plot(cluster_assignments[x][0], cluster_assignments[x][1], \"bo\")\n",
    "    plt.title(f\"Silhouette scores for {states[x]}\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Average silhouette score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal number of clusters per state: Odisha [0]; West Bengal [1]\n",
    "n_clusters = [6,8]\n",
    "centroids = []\n",
    "\n",
    "# Use the optimal number of clusters to assign clusters to the dishes (based on ingredients)\n",
    "for x in range(0, len(n_clusters)):\n",
    "    km = KModes(n_clusters = n_clusters[x], init='Huang', n_init=10, verbose=0, random_state = 10)\n",
    "    clusters = km.fit_predict(dfs_ing2[x])\n",
    "    centers = km.cluster_centroids_\n",
    "    centroids.append(centers)\n",
    "\n",
    "    # Add the cluster assignments to the appropriate dataframe\n",
    "    dfs_ing2[x][\"Clusters\"] = clusters\n",
    "    \n",
    "# Preview dataframe\n",
    "dfs_ing2[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the modes of each cluster \n",
    "# (non-zero nth element is an important feature of the cluster)\n",
    "for y in range(0, len(states)):\n",
    "    print(f\"State: {states[y]}\")\n",
    "    print(f\"Number of clusters: {len(centroids[y])}\")\n",
    "    print(f\"Number of ingredients: {len(centroids[y][0])}\")\n",
    "    print(\"\")\n",
    "    for x in list(range(0, n_clusters[y])):\n",
    "        print(f\"Cluster No.: {x}\")\n",
    "        print(\"--------------\")\n",
    "        print(centroids[y][x][0:-1])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the nth ingredient corresponding to the important feature of each cluster\n",
    "modes_state = []\n",
    "for y in centroids:\n",
    "    non_zeros1 = []\n",
    "    for x in range(0, len(y)):\n",
    "        non_zeros = [i for i,x in enumerate(y[x][0:-1].tolist()) if x > 0]\n",
    "        non_zeros1.append(non_zeros)\n",
    "    modes_state.append(non_zeros1)\n",
    "    \n",
    "modes_state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_ing2[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of lists of ingredients for Odisha [0] and West Bengal [1]\n",
    "ingredients_list = [list(df.columns) for df in dfs_ing2]\n",
    "\n",
    "for x in range(0, len(ingredients_list)):\n",
    "    print(f\"State: {states[x]}\")\n",
    "    print(\"------------------\")\n",
    "        \n",
    "    for h in range(0, len(modes_state[x])):\n",
    "        ingredients = [z for i, z in enumerate(ingredients_list[x]) if i in modes_state[x][h]]\n",
    "        print(f\"Cluster No.: {h}\")\n",
    "        dish_no = [i for i,w in enumerate(dfs_ing2[x][\"Clusters\"]) if w == h]\n",
    "        dish = [d for i,d in enumerate(list(dfs_ing2[x].index)) if i in dish_no]\n",
    "        print(\"Dishes:\")\n",
    "        print(*dish, sep = ', ')\n",
    "        print(\"\")\n",
    "        print(\"Ingredients:\")\n",
    "        print(*ingredients, sep = ', ')\n",
    "        print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns for each dataframe\n",
    "no_columns = [df.shape[1] - 1 for df in dfs_ing2]\n",
    "\n",
    "# Use Principal Component Analysis in visualising the data in 2D\n",
    "pca = PCA(2)\n",
    "\n",
    "for x in range(0, len(no_columns)):\n",
    "    plot_columns = pca.fit_transform(dfs_ing2[x].iloc[:,0: no_columns[x] - 1])   \n",
    "    plt.scatter(x = plot_columns[:,1], y = plot_columns[:,0], \n",
    "                c = dfs_ing2[x][\"Clusters\"], s = 30)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(f\"Principal Component Analysis for {states[x]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create co-occurrence matrix of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries of dish lists by occasion \n",
    "# 0 = Odisha; 1 = West Bengal\n",
    "dicts_ing_state = [dfs_ing[x].groupby(\"Dish\")[\"Ingredient2\"].apply(list).to_dict()\\\n",
    "                   for x in range(0, len(dfs_ing))]\n",
    "\n",
    "# Create a list of dish lists\n",
    "dish_ing_lists = [[dicts_ing_state[x][y] for y in dicts_ing_state[x]] \\\n",
    "              for x in range(0, len(dicts_ing_state))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of co-occurrence matrices\n",
    "coo_matrices_ing = []\n",
    "for x in range(0, len(states)):\n",
    "    data = list(itertools.chain.from_iterable(dish_ing_lists[x])) # flat list of dishes\n",
    "    matrix, vocab_index = coo_matrix(data)\n",
    "    data_matrix = pd.DataFrame(matrix, index=vocab_index, columns=vocab_index)\n",
    "    \n",
    "    # Save the co-occurrence matrix as csv\n",
    "    data_matrix.to_csv(f\"coo-matrix_ing_{states[x]}.csv\", header = True)\n",
    "    \n",
    "    # Append co-occurrence matrix to list   \n",
    "    coo_matrices_ing.append(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview one of the co-occurrence matrices\n",
    "coo_matrices_ing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of dishes and corresponding ingredients\n",
    "ingredients_dict = [df.groupby(\"Dish\")[\"Ingredient2\"].apply(list).to_dict() \\\n",
    "                    for df in dfs_ing]\n",
    "\n",
    "# Convert each list of ingredients into a string\n",
    "for dct in ingredients_dict:\n",
    "    for k in dct:\n",
    "        string = \" \".join(str(e) for e in dct[k])\n",
    "        dct[k] = string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
